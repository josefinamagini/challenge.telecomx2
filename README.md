# üìâ TelecomX ‚Äì Parte 2: Predicci√≥n de Cancelaci√≥n (Churn)

Este repositorio resume el trabajo del **Challenge TelecomX (Parte 2)** enfocado en la **predicci√≥n de cancelaci√≥n de clientes (churn)**.  
El objetivo es desarrollar modelos de Machine Learning que permitan anticipar qu√© clientes tienen mayor probabilidad de cancelar y proponer estrategias de retenci√≥n basadas en los resultados.

El informe completo, con visualizaciones, correlaciones y desempe√±o de modelos, se encuentra en el notebook del proyecto.

---

## üìÇ Estructura del proyecto
- `Notebooks` ‚Üí Notebook principal con el an√°lisis y modelado: **TelecomX_2.ipynb**  
- `Data` ‚Üí Dataset limpio exportado desde la Parte 1: **telecom_clean.csv**  
- `README.md` ‚Üí Este documento.  

El notebook realiza:
- Limpieza y preprocesamiento de datos (eliminaci√≥n de columnas irrelevantes, imputaci√≥n de nulos, codificaci√≥n con OneHotEncoder).  
- Exploraci√≥n de balance de clases y correlaciones.  
- An√°lisis dirigido (contrato vs churn, gasto total vs churn).  
- Entrenamiento de modelos (Regresi√≥n Log√≠stica y Random Forest).  
- Evaluaci√≥n con m√©tricas y visualizaci√≥n de matrices de confusi√≥n/curvas ROC.  
- Interpretaci√≥n de importancia de variables y conclusiones estrat√©gicas.

---

## ‚ñ∂Ô∏è C√≥mo ejecutar el proyecto
1. Abre el notebook en **Google Colab** o **Jupyter Notebook**.  
2. Ejecuta las celdas en orden. Se cargar√° `telecom_clean.csv`, se aplicar√° el preprocesamiento (encoding, imputaci√≥n, estandarizaci√≥n cuando necesario) y luego se entrenar√°n los modelos.  
3. Revisa la secci√≥n final con m√©tricas de desempe√±o y conclusiones.  
---

## üìä Resultados principales
**Tama√±o de muestra:** 5.813 clientes (despu√©s de limpiar registros `no answer`).  

### 1) Balance de clases (CustomerChurn)
- **Stayed (0):** ~71%  
- **Churned (1):** ~26%  
- **Eliminados (-1 / no answer):** ~3%  

Existe **desbalance moderado**, mitigado con `class_weight="balanced"` en los modelos.

### 2) Modelos evaluados
- **Regresi√≥n Log√≠stica (con normalizaci√≥n):**  
  - Accuracy: ~74%  
  - Precision: ~51%  
  - Recall: ~78%  
  - F1: ~61%  
  - ROC-AUC: ~84%  

- **Random Forest (sin normalizaci√≥n):**  
  - Accuracy: ~78%  
  - Precision: ~62%  
  - Recall: ~46%  
  - F1: ~53%  
  - ROC-AUC: ~82%  

### 3) Insights de variables
- **Contrato month-to-month** ‚Üí principal predictor de churn.  
- **Tenure (antig√ºedad)** bajo ‚Üí alto riesgo de cancelaci√≥n.  
- **Cargos mensuales altos** ‚Üí asociados a mayor deserci√≥n.  
- **Ausencia de TechSupport y OnlineSecurity** ‚Üí duplica probabilidad de churn.  
- **M√©todo de pago Electronic check** ‚Üí mayor volatilidad.  

---

## üß≠ Conclusiones e Insights
1. **Contratos mensuales** son el mayor factor de riesgo ‚Üí clientes con este plan muestran ~40% churn.  
2. **Clientes nuevos (Tenure ‚â§ 12 meses)** presentan mayor deserci√≥n ‚Üí etapa cr√≠tica de onboarding.  
3. **Servicios de soporte y seguridad (TechSupport, OnlineSecurity)** reducen churn casi a la mitad ‚Üí gran oportunidad de cross-sell defensivo.  
4. **M√©todo de pago Electronic check** correlaciona con m√°s cancelaciones ‚Üí migrar a m√©todos autom√°ticos mejora retenci√≥n.  
5. **Altos cargos mensuales** sin beneficios adicionales generan deserci√≥n ‚Üí sensibilidad al precio percibido.  

---

## üß© Recomendaciones
- **Migraci√≥n de contratos:** dise√±ar campa√±as para mover clientes de *month-to-month* a contratos anuales/bianuales con descuentos o bundles.  
- **Early-life care:** programas de fidelizaci√≥n y contacto proactivo en los primeros 90‚Äì120 d√≠as.  
- **Cross-sell estrat√©gico:** ofrecer **TechSupport** y **OnlineSecurity** como paquetes de fidelizaci√≥n.  
- **Incentivar m√©todos de pago autom√°ticos:** perks para quienes migren de Electronic check a d√©bito autom√°tico/tarjeta.  
- **Gesti√≥n de valor/precio:** revisar pricing de planes **Fiber optic** y cargos altos, comunicando beneficios tangibles.  

---

## ‚ùó Posibles problemas y soluciones
- **Valores nulos (NaN):** fueron tratados con imputaci√≥n (mediana/moda).  
- **Desbalance de clases:** mitigado con `class_weight="balanced"`, pero se sugiere probar t√©cnicas de oversampling (SMOTE).  
- **Overfitting potencial en Random Forest:** ajustar hiperpar√°metros (n_estimators, max_depth).  

---

## üöÄ Tecnolog√≠as utilizadas
- **Python 3.x**  
- `pandas` / `numpy` ‚Üí manipulaci√≥n y preparaci√≥n de datos  
- `matplotlib` / `seaborn` ‚Üí visualizaciones  
- `scikit-learn` ‚Üí pipelines de ML, modelos y m√©tricas  
- Google Colab / Jupyter ‚Üí entorno de ejecuci√≥n  

---

## üë©‚Äçüíª Autora
Proyecto desarrollado por **Josefina Magini**  
Challenge Final ‚Äì *Data Science Student*  
TelecomX ‚Äî Parte 2
